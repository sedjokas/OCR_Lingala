# -*- coding: utf-8 -*-
"""Fine-tuning LayoutLM_VERSION_F.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XJb7CQQW9RZvYepLKrGFcgbFOUN2pVWg

## Setting up environment

First, we install the ü§ó transformers and datasets libraries, as well as the [Tesseract OCR engine](https://github.com/tesseract-ocr/tesseract) (built by Google). LayoutLM requires an external OCR engine of choice to turn a document into a list of words and bounding boxes.
"""

from google.colab import drive
drive.mount('/content/drive')

pip install torchmetrics

! pip install transformers datasets

! sudo apt install tesseract-ocr
! pip install pytesseract

# import requests
# import zipfile
# import io

# def download_data():
#     url = "https://www.dropbox.com/s/kuw05qmc4uy474d/RVL_CDIP_one_example_per_class.zip?dl=1"
#     r = requests.get(url)
#     z = zipfile.ZipFile(io.BytesIO(r.content))
#     z.extractall('/content/drive/MyDrive/DataLayoutLM')  # Chemin cible dans votre Drive

# download_data()

# import requests, zipfile, io

# def download_data():
#     url = "https://www.dropbox.com/s/kuw05qmc4uy474d/RVL_CDIP_one_example_per_class.zip?dl=1"
#     r = requests.get(url)
#     z = zipfile.ZipFile(io.BytesIO(r.content))
#     z.extractall()

# download_data()

"""Let's look at a random training example (in this case, a resume):"""

from PIL import Image, ImageDraw, ImageFont

image = Image.open("/content/drive/MyDrive/DataLayoutLM/image_10/image_10.tiff")
image = image.convert("RGB")
image

"""We can use the Tesseract OCR engine to turn the image into a list of recognized words:"""

import pytesseract
import numpy as np

ocr_df = pytesseract.image_to_data(image, output_type='data.frame')
ocr_df = ocr_df.dropna().reset_index(drop=True)
float_cols = ocr_df.select_dtypes('float').columns
ocr_df[float_cols] = ocr_df[float_cols].round(0).astype(int)
ocr_df = ocr_df.replace(r'^\s*$', np.nan, regex=True)
words = ' '.join([word for word in ocr_df.text if str(word) != 'nan'])
words

"""We can also visualize the bounding boxes of the recognized words, as follows:"""

coordinates = ocr_df[['left', 'top', 'width', 'height']]
actual_boxes = []
for idx, row in coordinates.iterrows():
    x, y, w, h = tuple(row) # the row comes in (left, top, width, height) format
    actual_box = [x, y, x+w, y+h] # we turn it into (left, top, left+width, top+height) to get the actual box
    actual_boxes.append(actual_box)

draw = ImageDraw.Draw(image, "RGB")
for box in actual_boxes:
  draw.rectangle(box, outline='red')

image

"""## Preprocessing the data using ü§ó datasets

First, we convert the dataset into a Pandas dataframe, having 2 columns: `image_path` and `label`.
"""

import pandas as pd
import os

dataset_path = "/content/drive/MyDrive/DataLayoutLM"
labels = [label for label in os.listdir(dataset_path)]
idx2label = {v: k for v, k in enumerate(labels)}
label2idx = {k: v for v, k in enumerate(labels)}
label2idx

# import os
# from PIL import Image

# # Chemin du dossier contenant les fichiers PNG
# input_folder = '/content/drive/MyDrive/data/training_data/images'

# # Chemin du dossier parent o√π les TIFF seront enregistr√©s
# output_folder = '/content/drive/MyDrive/DataLayoutLM'

# # Cr√©er le dossier parent s'il n'existe pas
# os.makedirs(output_folder, exist_ok=True)

# # Parcourir chaque fichier dans le dossier d'entr√©e
# for file_name in os.listdir(input_folder):
#     if file_name.endswith('.png'):
#         # Cr√©er un sous-dossier pour chaque fichier TIFF
#         subfolder_path = os.path.join(output_folder, file_name.split('.')[0])
#         os.makedirs(subfolder_path, exist_ok=True)

#         # Chemin complet du fichier source PNG
#         input_path = os.path.join(input_folder, file_name)

#         # Chemin complet du fichier de sortie TIFF
#         output_path = os.path.join(subfolder_path, file_name.replace('.png', '.tiff'))

#         # Charger l'image PNG et la sauvegarder en TIFF
#         image = Image.open(input_path)
#         image.save(output_path, format='TIFF')

# print("Conversion termin√©e avec succ√®s !")

# import os
# import pandas as pd

# images = []
# labels = []

# # Assurez-vous que dataset_path est correctement d√©fini
# dataset_path = '/content/drive/MyDrive/DataLayoutLM'

# for label_folder, _, file_names in os.walk(dataset_path):
#     if label_folder != dataset_path:
#         label = label_folder[len(dataset_path)+1:]  # Extraire correctement le nom du label
#         for image in file_names:
#             # Construction correcte du chemin d'acc√®s √† l'image
#             image_path = os.path.join(label_folder, image)
#             images.append(image_path)
#             labels.append(label)

# # Cr√©ation du DataFrame
# data = pd.DataFrame.from_dict({'image_path': images, 'label': labels})
# print(data.head())

# images = []
# labels = []

# for label_folder, _, file_names in os.walk(dataset_path):
#   if label_folder != dataset_path:
#     label = label_folder[40:]
#     for _, _, image_names in os.walk(label_folder):
#       relative_image_names = []
#       for image in image_names:
#         relative_image_names.append(dataset_path + "/" + label + "/" + image)
#       images.extend(relative_image_names)
#       labels.extend([label] * len (relative_image_names))

# data = pd.DataFrame.from_dict({'image_path': images, 'label': labels})
# data.head()

import os
import pandas as pd

images = []
labels = []

for label_folder, _, file_names in os.walk(dataset_path):
  if label_folder != dataset_path:
    label = os.path.basename(label_folder)  # Utiliser basename pour extraire le nom du label
    for _, _, image_names in os.walk(label_folder):
      relative_image_names = []
      for image in image_names:
        relative_image_names.append(os.path.join(dataset_path, label, image))
      images.extend(relative_image_names)
      labels.extend([label] * len(relative_image_names))

data = pd.DataFrame.from_dict({'image_path': images, 'label': labels})
data.head()

len(data)

"""Now, let's apply OCR to get the words and bounding boxes of every image. To do this efficiently, we turn our Pandas dataframe into a HuggingFace `Dataset` object, and use the `.map()` functionality to get the words and normalized bounding boxes of every image. Note that this can take a while to run (Tesseract seems a bit slow)."""

from datasets import Dataset

def normalize_box(box, width, height):
     return [
         int(1000 * (box[0] / width)),
         int(1000 * (box[1] / height)),
         int(1000 * (box[2] / width)),
         int(1000 * (box[3] / height)),
     ]

def apply_ocr(example):
        # get the image
        image = Image.open(example['image_path'])

        width, height = image.size

        # apply ocr to the image
        ocr_df = pytesseract.image_to_data(image, output_type='data.frame')
        float_cols = ocr_df.select_dtypes('float').columns
        ocr_df = ocr_df.dropna().reset_index(drop=True)
        ocr_df[float_cols] = ocr_df[float_cols].round(0).astype(int)
        ocr_df = ocr_df.replace(r'^\s*$', np.nan, regex=True)
        ocr_df = ocr_df.dropna().reset_index(drop=True)

        # get the words and actual (unnormalized) bounding boxes
        #words = [word for word in ocr_df.text if str(word) != 'nan'])
        words = list(ocr_df.text)
        words = [str(w) for w in words]
        coordinates = ocr_df[['left', 'top', 'width', 'height']]
        actual_boxes = []
        for idx, row in coordinates.iterrows():
            x, y, w, h = tuple(row) # the row comes in (left, top, width, height) format
            actual_box = [x, y, x+w, y+h] # we turn it into (left, top, left+width, top+height) to get the actual box
            actual_boxes.append(actual_box)

        # normalize the bounding boxes
        boxes = []
        for box in actual_boxes:
            boxes.append(normalize_box(box, width, height))

        # add as extra columns
        assert len(words) == len(boxes)
        example['words'] = words
        example['bbox'] = boxes
        return example

dataset = Dataset.from_pandas(data)
updated_dataset = dataset.map(apply_ocr)

"""Next, we can turn the word-level 'words' and 'bbox' columns into token-level `input_ids`, `attention_mask`, `bbox` and `token_type_ids` using `LayoutLMTokenizer`."""

from transformers import LayoutLMTokenizer
import torch

tokenizer = LayoutLMTokenizer.from_pretrained("microsoft/layoutlm-base-uncased")

def encode_example(example, max_seq_length=512, pad_token_box=[0, 0, 0, 0]):
  words = example['words']
  normalized_word_boxes = example['bbox']

  assert len(words) == len(normalized_word_boxes)

  token_boxes = []
  for word, box in zip(words, normalized_word_boxes):
      word_tokens = tokenizer.tokenize(word)
      token_boxes.extend([box] * len(word_tokens))

  # Truncation of token_boxes
  special_tokens_count = 2
  if len(token_boxes) > max_seq_length - special_tokens_count:
      token_boxes = token_boxes[: (max_seq_length - special_tokens_count)]

  # add bounding boxes of cls + sep tokens
  token_boxes = [[0, 0, 0, 0]] + token_boxes + [[1000, 1000, 1000, 1000]]

  encoding = tokenizer(' '.join(words), padding='max_length', truncation=True)
  # Padding of token_boxes up the bounding boxes to the sequence length.
  input_ids = tokenizer(' '.join(words), truncation=True)["input_ids"]
  padding_length = max_seq_length - len(input_ids)
  token_boxes += [pad_token_box] * padding_length
  encoding['bbox'] = token_boxes
  encoding['label'] = label2idx[example['label']]

  assert len(encoding['input_ids']) == max_seq_length
  assert len(encoding['attention_mask']) == max_seq_length
  assert len(encoding['token_type_ids']) == max_seq_length
  assert len(encoding['bbox']) == max_seq_length

  return encoding

# from datasets import Features, Sequence, ClassLabel, Value, Array2D

# # Nombre de classes distinctes
# num_classes = 31  # Ou le nombre appropri√© bas√© sur votre analyse des donn√©es

# # Noms des classes
# class_names = [f'image_{i+1}' for i in range(num_classes)]

# features = Features({
#     'input_ids': Sequence(feature=Value(dtype='int64')),
#     'bbox': Array2D(dtype="int64", shape=(512, 4)),
#     'attention_mask': Sequence(Value(dtype='int64')),
#     'token_type_ids': Sequence(Value(dtype='int64')),
#     'label': ClassLabel(num_classes=num_classes, names=class_names),
#     'image_path': Value(dtype='string'),
#     'words': Sequence(feature=Value(dtype='string')),
# })

# encoded_dataset = updated_dataset.map(lambda example: encode_example(example),
#                                       features=features)

from datasets import Features, Sequence, ClassLabel, Value, Array2D



num_classes = 30  # Mettez √† jour ce nombre selon l'analyse de vos donn√©es

features = Features({
    'input_ids': Sequence(feature=Value(dtype='int64')),
    'bbox': Array2D(dtype="int64", shape=(512, 4)),
    'attention_mask': Sequence(Value(dtype='int64')),
    'token_type_ids': Sequence(Value(dtype='int64')),
    'label': ClassLabel(num_classes=num_classes, names=[f'class_{i}' for i in range(num_classes)]),
    'image_path': Value(dtype='string'),
    'words': Sequence(feature=Value(dtype='string')),
})


encoded_dataset = updated_dataset.map(lambda example: encode_example(example),
                                      features=features)

"""Finally, we set the format to PyTorch, as the LayoutLM implementation in the Transformers library is in PyTorch. We also specify which columns we are going to use."""

encoded_dataset.set_format(type='torch', columns=['input_ids', 'bbox', 'attention_mask', 'token_type_ids', 'label'])

print(len(encoded_dataset))

dataloader = torch.utils.data.DataLoader(encoded_dataset, batch_size=1, shuffle=True)
batch = next(iter(dataloader))
batch

"""Let's verify whether the input ids are created correctly by decoding them back to text:"""

tokenizer.decode(batch['input_ids'][0].tolist())

idx2label[batch['label'][0].item()]

"""## Define the model

Here we define the model, namely `LayoutLMForSequenceClassification`. We initialize it with the weights of the pre-trained base model (`LayoutLMModel`). The weights of the classification head are randomly initialized, and will be fine-tuned together with the weights of the base model on our tiny dataset. Once loaded, we move it to the GPU.


"""

from transformers import LayoutLMForSequenceClassification
import torch

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = LayoutLMForSequenceClassification.from_pretrained("microsoft/layoutlm-base-uncased", num_labels=len(label2idx))
model.to(device)

"""## Train the model

Here we train the model in familiar PyTorch fashion. We use the Adam optimizer with weight decay fix (normally you can also specify which variables should have weight decay and which not + a learning rate scheduler, see [here](https://github.com/microsoft/unilm/blob/5d16c846bec56b6e88ec7de4fc3ceb7c803571a4/layoutlm/examples/classification/run_classification.py#L94) for how the authors of LayoutLM did this), and train for 30 epochs. If the model is able to overfit it, then it means there are no issues and we can train it on the entire dataset.
"""

import torch
from torch.optim import AdamW
from transformers import get_linear_schedule_with_warmup

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# Assurez-vous que 'dataloader' est bien d√©fini et initialis√© avant de calculer 't_total'
num_train_epochs = 50  # Nombre d'√©poques pour l'entra√Ænement
t_total = len(dataloader) * num_train_epochs  # Nombre total de pas d'entra√Ænement

optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=t_total)

global_step = 0

# D√©but de la boucle d'entra√Ænement
model.train()
for epoch in range(num_train_epochs):
    print("Epoch:", epoch)
    running_loss = 0.0
    correct = 0
    total = 0  # Compteur pour le total des √©chantillons trait√©s

    for batch in dataloader:
        input_ids = batch["input_ids"].to(device)
        bbox = batch["bbox"].to(device)
        attention_mask = batch["attention_mask"].to(device)
        token_type_ids = batch["token_type_ids"].to(device)
        labels = batch["label"].to(device)

        optimizer.zero_grad()
        outputs = model(input_ids=input_ids, bbox=bbox, attention_mask=attention_mask, token_type_ids=token_type_ids, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        scheduler.step()  # Mise √† jour du schedule de l'apprentissage apr√®s l'optimizer step

        running_loss += loss.item()
        predictions = outputs.logits.argmax(-1)
        correct += (predictions == labels).float().sum()
        total += labels.size(0)

    epoch_loss = running_loss / len(dataloader)
    epoch_accuracy = 100 * correct / total

    print("Training Loss:", epoch_loss)
    print("Training accuracy:", epoch_accuracy.item())

import argparse

def evaluate(args, model, tokenizer, mode="val", prefix=""):
    """Fonction pour √©valuer le mod√®le sur un ensemble de donn√©es donn√©."""
    eval_dataset = load_and_cache_examples(args, tokenizer, mode=mode)

    if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:
        os.makedirs(args.output_dir)

    eval_sampler = SequentialSampler(eval_dataset)
    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.per_gpu_eval_batch_size)

    # Mise en √©valuation du mod√®le
    model.eval()
    eval_loss = 0.0
    nb_eval_steps = 0
    preds = None
    out_label_ids = None

    for batch in tqdm(eval_dataloader, desc="Evaluating"):
        batch = tuple(t.to(args.device) for t in batch)

        with torch.no_grad():
            inputs = {
                'input_ids': batch[0],
                'attention_mask': batch[1],
                'labels': batch[3],
            }

            if args.model_type == "layoutlm":
                inputs['bbox'] = batch[4]

            if 'token_type_ids' in inputs:
                inputs['token_type_ids'] = batch[2] if args.model_type in ['bert', 'layoutlm'] else None

            outputs = model(**inputs)
            tmp_eval_loss, logits = outputs[:2]

            eval_loss += tmp_eval_loss.mean().item()
        nb_eval_steps += 1

        if preds is None:
            preds = logits.detach().cpu().numpy()
            out_label_ids = inputs['labels'].detach().cpu().numpy()
        else:
            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)
            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)

    eval_loss = eval_loss / nb_eval_steps
    preds = np.argmax(preds, axis=1)
    result = simple_accuracy(preds, out_label_ids)
    results = {"eval_loss": eval_loss, "eval_accuracy": result}

    output_eval_file = os.path.join(args.output_dir, prefix, "eval_results.txt")
    with open(output_eval_file, "w") as writer:
        for key in sorted(results.keys()):
            writer.write("%s = %s\n" % (key, str(results[key])))

    return results

def main():
    # Parse the arguments (assuming this is already done in the upper part of your script)
    args = parser.parse_args()

    # Setup CUDA, GPU & distributed training
    # This should also be part of your initial setup

    # Load pretrained model and tokenizer
    model, tokenizer = load_model_and_tokenizer(args)

    # Training
    if args.do_train:
        train_dataset = load_and_cache_examples(args, tokenizer, mode="train")
        global_step, tr_loss = train(args, train_dataset, model, tokenizer)
        logger.info("Global step: %s, Training loss: %s", global_step, tr_loss)

    # Evaluation
    if args.do_eval:
        result = evaluate(args, model, tokenizer)
        logger.info("Validation results: %s", result)

    return result


def setup_arg_parser():
    """Fonction pour configurer et retourner l'analyseur d'arguments."""
    parser = argparse.ArgumentParser()

    # Param√®tres requis
    parser.add_argument("--data_dir", type=str, required=True, help="Chemin vers le r√©pertoire de donn√©es.")
    parser.add_argument("--model_type", type=str, required=True, help="Type de mod√®le: bert, roberta, ou layoutlm.")
    parser.add_argument("--model_name_or_path", type=str, required=True, help="Chemin vers le mod√®le pr√©-entra√Æn√© ou son nom.")
    parser.add_argument("--output_dir", type=str, required=True, help="R√©pertoire o√π les sorties seront sauvegard√©es.")

    # Autres param√®tres
    parser.add_argument("--config_name", type=str, help="Nom ou chemin vers la configuration pr√©-entra√Æn√©e.")
    parser.add_argument("--tokenizer_name", type=str, help="Nom ou chemin vers le tokenizer pr√©-entra√Æn√©.")
    parser.add_argument("--max_seq_length", default=512, type=int, help="Longueur maximale des s√©quences d'entr√©e.")
    parser.add_argument("--do_train", action='store_true', help="D√©finir ce flag pour activer l'entra√Ænement.")
    parser.add_argument("--do_eval", action='store_true', help="D√©finir ce flag pour activer l'√©valuation.")
    parser.add_argument("--do_test", action='store_true', help="D√©finir ce flag pour activer les tests.")
    parser.add_argument("--per_gpu_train_batch_size", default=8, type=int, help="Taille de lot par GPU pour l'entra√Ænement.")
    parser.add_argument("--per_gpu_eval_batch_size", default=8, type=int, help="Taille de lot par GPU pour l'√©valuation.")
    parser.add_argument("--learning_rate", default=5e-5, type=float, help="Taux d'apprentissage initial.")
    parser.add_argument("--num_train_epochs", default=3, type=float, help="Nombre total d'√©poques d'entra√Ænement.")
    parser.add_argument("--seed", type=int, default=42, help="Graine al√©atoire pour la reproductibilit√©.")

    return parser

def main():
    parser = setup_arg_parser()
    args = parser.parse_args()

    # Configuration de CUDA, GPU et entra√Ænement distribu√© selon les arguments
    ...

if __name__ == "__main__":
    main()

import matplotlib.pyplot as plt

epochs = range(num_train_epochs)

plt.plot(epochs, train_accuracies, 'b', label='Training accuracy', color ='tab:blue')
plt.plot(epochs, val_accuracies, 'b', label='Validation accuracy', color ='tab:orange')
plt.title('Training and validation accuracy')
plt.legend()
plt.figure()

plt.plot(epochs, train_losses, 'b', label='Training Loss', color ='tab:blue')
plt.plot(epochs, val_losses, 'b', label='Validation Loss', color ='tab:orange')
plt.title('Training and validation loss')
plt.legend()

plt.show()

import torch
from torch.optim import AdamW
import torchmetrics
from transformers import get_linear_schedule_with_warmup

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

num_train_epochs = 3
t_total = len(dataloader) * num_train_epochs  # Total number of training steps

optimizer = AdamW(model.parameters(), lr=5e-5)
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=t_total)

# D√©finissez le nombre de classes ici
nombre_de_classes = 30  # Remplacez par le nombre r√©el de classes dans votre probl√®me

# Initialisation des m√©triques en sp√©cifiant le type de t√¢che
accuracy_metric = torchmetrics.Accuracy(num_classes=nombre_de_classes, average='macro', task='multiclass').to(device)
precision_metric = torchmetrics.Precision(num_classes=nombre_de_classes, average='macro', task='multiclass').to(device)
recall_metric = torchmetrics.Recall(num_classes=nombre_de_classes, average='macro', task='multiclass').to(device)
f1_metric = torchmetrics.F1Score(num_classes=nombre_de_classes, average='macro', task='multiclass').to(device)

# Suite de votre code pour l'entra√Ænement...


global_step = 0

# Mettre le mod√®le en mode entra√Ænement
model.train()

for epoch in range(num_train_epochs):
    print("Epoch:", epoch)
    running_loss = 0.0
    correct = 0
    total = 0  # Ajouter un compteur pour le total des √©chantillons trait√©s

    for batch in dataloader:
        input_ids = batch["input_ids"].to(device)
        bbox = batch["bbox"].to(device)
        attention_mask = batch["attention_mask"].to(device)
        token_type_ids = batch["token_type_ids"].to(device)
        labels = batch["label"].to(device)

        optimizer.zero_grad()  # R√©initialiser les gradients avant le calcul

        # Forward pass
        outputs = model(input_ids=input_ids, bbox=bbox, attention_mask=attention_mask, token_type_ids=token_type_ids, labels=labels)
        loss = outputs.loss
        running_loss += loss.item()

        # Backward pass pour obtenir les gradients
        loss.backward()

        # Mise √† jour
        optimizer.step()
        scheduler.step()  # Mise √† jour du schedule de l'apprentissage apr√®s l'optimizer step

        predictions = outputs.logits.argmax(-1)
        accuracy_metric.update(predictions, labels)
        precision_metric.update(predictions, labels)
        recall_metric.update(predictions, labels)
        f1_metric.update(predictions, labels)

    # Affichage des m√©triques pour l'√©poque
    epoch_loss = running_loss / len(dataloader)
    epoch_accuracy = accuracy_metric.compute()
    epoch_precision = precision_metric.compute()
    epoch_recall = recall_metric.compute()
    epoch_f1 = f1_metric.compute()

    print(f"Epoch {epoch}: Loss = {epoch_loss}, Accuracy = {epoch_accuracy}, Precision = {epoch_precision}, Recall = {epoch_recall}, F1 = {epoch_f1}")

    accuracy_metric.reset()
    precision_metric.reset()
    recall_metric.reset()
    f1_metric.reset()

from torch.utils.data import Dataset, DataLoader
import pytesseract
import numpy as np

class Dataset(Dataset):
    """RVL-CDIP dataset (small subset)."""

    def __init__(self, data, tokenizer):
        self.data = data
        self.tokenizer = tokenizer

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        # get the image
        image = Image.open(data.iloc[idx].image_path)

        width, height = image.size

        # apply ocr to the image
        ocr_df = pytesseract.image_to_data(image, output_type='data.frame')
        float_cols = ocr_df.select_dtypes('float').columns
        ocr_df[float_cols] = ocr_df[float_cols].round(0).astype(int)
        ocr_df = ocr_df.replace(r'^\s*$', np.nan, regex=True)
        ocr_df = ocr_df.dropna().reset_index(drop=True)

        # get the words and actual (unnormalized) bounding boxes
        words = list(ocr_df.text)
        coordinates = ocr_df[['left', 'top', 'width', 'height']]
        actual_boxes = []
        for idx, row in coordinates.iterrows():
            x, y, w, h = tuple(row) # the row comes in (left, top, width, height) format
            actual_box = [x, y, x+w, y+h] # we turn it into (left, top, left+widght, top+height) to get the actual box
            actual_boxes.append(actual_box)

        # normalize the bounding boxes
        boxes = []
        for box in actual_boxes:
            boxes.append(normalize_box(box, width, height))

        # convert to token-level features
        encoding = convert_example_to_features(image, words, boxes, actual_boxes, self.tokenizer)

        # add the label
        print(idx)
        label = data.iloc[idx].label
        encoding["label"] = torch.tensor(label2idx[label])

        return encoding